{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# SkinLesion - Desafio ISIC 2019\n",
    "## CNNs\n",
    "### Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Open dataframes containing the images for training, validation and test\n",
    "train_df = pd.read_csv(r\"isic2019_train.csv\")\n",
    "aug_df = pd.read_csv(r\"isic2019_train_aug_full.csv\")\n",
    "val_df = pd.read_csv(r\"isic2019_val.csv\")\n",
    "test_df = pd.read_csv(r\"isic2019_test.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Informações sobre os *datasets* de treino, validação e teste"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train dataframe WITHOUT data augmentation\n",
    "print(train_df.info(), end='\\n\\n')\n",
    "aug_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Augmented train dataframe\n",
    "print(aug_df.info(), end='\\n\\n')\n",
    "aug_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Validation dataframe\n",
    "print(val_df.info(), end='\\n\\n')\n",
    "val_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test dataframe\n",
    "print(test_df.info(), end='\\n\\n')\n",
    "test_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Geradores dos tensores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMG_SIZE = 260\n",
    "\n",
    "train_dataGen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_dataGen.flow_from_dataframe(dataframe=aug_df, x_col='image_path', class_mode='raw',\n",
    "                                                    seed=31415,\n",
    "                                                    y_col=['MEL', 'NV', 'BCC', 'AK', 'BKL', 'DF', 'VASC', 'SCC'],\n",
    "                                                    target_size=(IMG_SIZE, IMG_SIZE), batch_size=32)\n",
    "\n",
    "val_generator = train_dataGen.flow_from_dataframe(dataframe=val_df, x_col='image_path', class_mode='raw', seed=31415,\n",
    "                                                    y_col=['MEL', 'NV', 'BCC', 'AK', 'BKL', 'DF', 'VASC', 'SCC'],\n",
    "                                                    target_size=(IMG_SIZE, IMG_SIZE), batch_size=32)\n",
    "\n",
    "test_generator = train_dataGen.flow_from_dataframe(dataframe=test_df, x_col='image_path', class_mode='raw', seed=31415,\n",
    "                                                    y_col=['MEL', 'NV', 'BCC', 'AK', 'BKL', 'DF', 'VASC', 'SCC'],\n",
    "                                                    target_size=(IMG_SIZE, IMG_SIZE), batch_size=32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dependências\n",
    "#### Métricas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Method for specificity metric\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# F1 score\n",
    "class F1_Score(tf.keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.f1 = self.add_weight(name='f1', initializer='zeros')\n",
    "        self.precision_fn = Precision(thresholds=0.5)\n",
    "        self.recall_fn = Recall(thresholds=0.5)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        p = self.precision_fn(y_true, y_pred)\n",
    "        r = self.recall_fn(y_true, y_pred)\n",
    "        # since f1 is a variable, we use assign\n",
    "        self.f1.assign(2 * ((p * r) / (p + r + 1e-6)))\n",
    "\n",
    "    def result(self):\n",
    "        return self.f1\n",
    "\n",
    "    def reset_states(self):\n",
    "        # we also need to reset the state of the precision and recall objects\n",
    "        self.precision_fn.reset_states()\n",
    "        self.recall_fn.reset_states()\n",
    "        self.f1.assign(0)\n",
    "\n",
    "f1_score = F1_Score()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Imports p/ arquiteturas desenvolvidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.layers import GlobalAvgPool2D"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ResNet-34"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "\n",
    "# Residual units\n",
    "class ResidualUnit(keras.layers.Layer):\n",
    "    def __init__(self, filters, strides=1, activation='relu', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        self.main_layers = [keras.layers.Conv2D(filters, 3, strides=strides, padding='same', use_bias=False),\n",
    "                            keras.layers.BatchNormalization(),\n",
    "                            self.activation,\n",
    "                            keras.layers.Conv2D(filters, 3, strides=1, padding='same', use_bias=False),\n",
    "                            keras.layers.BatchNormalization()]\n",
    "        self.skip_layers = []\n",
    "\n",
    "        if strides > 1:\n",
    "            self.skip_layers = [keras.layers.Conv2D(filters, 1, strides=strides, padding='same', use_bias=False),\n",
    "                                keras.layers.BatchNormalization()]\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "\n",
    "        for layer in self.main_layers:\n",
    "            Z = layer(Z)\n",
    "\n",
    "        skip_Z = inputs\n",
    "\n",
    "        for layer in self.skip_layers:\n",
    "            skip_Z = layer(skip_Z)\n",
    "\n",
    "        return self.activation(Z + skip_Z)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ResNet-34 implementation as in Hands-On ML book\n",
    "resnet34 = keras.models.Sequential()\n",
    "\n",
    "# Convolutional layer\n",
    "resnet34.add(Conv2D(64, 7, strides=2, input_shape=[224, 224, 3], padding='same', use_bias=False))\n",
    "resnet34.add(BatchNormalization())\n",
    "resnet34.add(Activation('relu'))\n",
    "resnet34.add(MaxPooling2D(pool_size=3, strides=2, padding='same'))\n",
    "\n",
    "# Residual units layers\n",
    "prev_filters = 64\n",
    "for filters in [64] * 3 + [128] * 4 + [256] * 6 + [512] * 3:\n",
    "    strides = 1 if filters == prev_filters else 2\n",
    "\n",
    "    resnet34.add(ResidualUnit(filters, strides=strides))\n",
    "\n",
    "    prev_filters = filters\n",
    "\n",
    "# Output layers\n",
    "resnet34.add(GlobalAvgPool2D())\n",
    "resnet34.add(Flatten())\n",
    "resnet34.add(Dense(8, activation='softmax'))\n",
    "\n",
    "# Compile\n",
    "resnet34.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy', AUC(name=\"AUC\"), Recall(name=\"Recall\"), specificity, Precision(name=\"Precision\"),\n",
    "                          f1_score])\n",
    "\n",
    "# Summary\n",
    "resnet34.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train with callback (early stopping)\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "history = resnet34.fit(train_generator, validation_data=val_generator, epochs=50, callbacks=[callback])\n",
    "\n",
    "# Train model\n",
    "# history = resnet34.fit(train_generator, validation_data=val_generator, epochs=30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = resnet34.evaluate(test_generator, batch_size=128)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Rede neural convolucional"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "# 1s conv layer\n",
    "classifier.add(Conv2D(filters=64, kernel_size=(7,7), activation='relu', input_shape=(384, 384, 3), strides=3))\n",
    "# pooling layer\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# 2nd conv layer\n",
    "classifier.add(Conv2D(128, (3,3), activation='relu'))\n",
    "classifier.add(Conv2D(128, (3,3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# 3rd conv layer\n",
    "classifier.add(Conv2D(256, (3,3), activation='relu'))\n",
    "classifier.add(Conv2D(256, (3,3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Flatten\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(units=64, activation='relu'))\n",
    "classifier.add(Dropout(rate=0.5))\n",
    "\n",
    "# Hidden layer\n",
    "classifier.add(Dense(units=64, activation='relu'))\n",
    "classifier.add(Dropout(rate=0.5))\n",
    "classifier.add(Dense(units=32, activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "classifier.add(Dense(9, activation='softmax'))\n",
    "\n",
    "# Compile network\n",
    "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# classifier.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "#                    metrics=['accuracy', Precision(), Recall(), AUC()])\n",
    "\n",
    "classifier.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = classifier.fit(train_generator, validation_data=val_generator, epochs=50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_predictions = classifier.predict(test_generator, batch_size=128)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history.history.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(test_generator.labels.argmax(1), test_predictions.argmax(1), zero_division=0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Confusion matrix\n",
    "plt.matshow(confusion)\n",
    "\n",
    "confusion = tf.math.confusion_matrix(test_generator.labels.argmax(1), test_predictions.argmax(1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Salvar/Carregar modelo ou pesos"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save model's current weights (CAUTION: defaults to overwrite)\n",
    "# model.save_weights('./models/efficientNetB3_topTrained')\n",
    "\n",
    "# Load model (the whole model, including architecture and weights)\n",
    "# model = tf.keras.models.load_model('./models/efficientNetB2_topTrained.tf')\n",
    "\n",
    "# Load model weights\n",
    "# model.load_weights('./models/efficientNetB3_topTrained')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Resultados"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### ResNet-34\n",
    "##### 1° Teste\n",
    "- Usando:\n",
    "  - Split estratificado;\n",
    "  - **1° conjunto de data augmentation**;\n",
    "  - *Early stop* (`patience=5`):\n",
    "    - Parou na 12ª época:\n",
    "- Resultados do teste:\n",
    "  - 38s 2s/step;\n",
    "  - Loss: 1.1328;\n",
    "  - Accuracy: 0.6054;\n",
    "  - Precision: 0.6930;\n",
    "  - Recall: 0.5264;\n",
    "  - AUC: 0.9116.\n",
    "\n",
    "##### 2° Teste\n",
    "- Usando:\n",
    "  - Split estratificado;\n",
    "  - **1° conjunto de data augmentation**;\n",
    "  - Parada após 30 épocas.\n",
    "- Resultados do teste:\n",
    "  - 37s 2s/step;\n",
    "  - Loss: 2.2576;\n",
    "  - Accuracy: 0.6326;\n",
    "  - Precision: 0.6376;\n",
    "  - Recall: 0.6271;\n",
    "  - AUC: 0.8746."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for recall\n",
    "plt.plot(history.history['recall_1'])\n",
    "plt.plot(history.history['val_recall_1'])\n",
    "plt.title('Model recall')\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for precision\n",
    "plt.plot(history.history['precision_1'])\n",
    "plt.plot(history.history['val_precision_1'])\n",
    "plt.title('Model precision')\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for auc\n",
    "plt.plot(history.history['auc_1'])\n",
    "plt.plot(history.history['val_auc_1'])\n",
    "plt.title('Model AUC')\n",
    "plt.ylabel('AUC')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### ResNet-34: 3° Teste\n",
    "- Usando:\n",
    "  - Split estratificado;\n",
    "  - **Ambos conjuntos de data augmentation**;\n",
    "  - Parada após 19 épocas;\n",
    "  - Teste executado com a época de melhor resultado (9).\n",
    "- Resultados do teste:\n",
    "  - 38s 2s/step;\n",
    "  - Loss: 1.0280;\n",
    "  - Accuracy: 0.6263;\n",
    "  - Precision: 0.7632\n",
    "  - Recall: 0.5063\n",
    "  - AUC: 0.9226"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for recall\n",
    "plt.plot(history.history['recall_2'])\n",
    "plt.plot(history.history['val_recall_2'])\n",
    "plt.title('Model recall')\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for precision\n",
    "plt.plot(history.history['precision_2'])\n",
    "plt.plot(history.history['val_precision_2'])\n",
    "plt.title('Model precision')\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for auc\n",
    "plt.plot(history.history['auc_2'])\n",
    "plt.plot(history.history['val_auc_2'])\n",
    "plt.title('Model AUC')\n",
    "plt.ylabel('AUC')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### ResNet-34: 4° Teste\n",
    "- Usando:\n",
    "  - Split estratificado;\n",
    "  - DS **sem** data augmentation;\n",
    "  - Early stopping:\n",
    "    - Parada após 24 épocas;\n",
    "    - Teste executado com a época de melhor resultado (14).\n",
    "- Resultados do teste:\n",
    "  - 35s 2s/step;\n",
    "  - Loss: 1.0600;\n",
    "  - Accuracy: 0.6247;\n",
    "  - Precision: 0.7225;\n",
    "  - Recall: 0.5517;\n",
    "  - AUC: 0.9220."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for recall\n",
    "plt.plot(history.history['Recall'])\n",
    "plt.plot(history.history['val_Recall'])\n",
    "plt.title('Model recall')\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for precision\n",
    "plt.plot(history.history['Precision'])\n",
    "plt.plot(history.history['val_Precision'])\n",
    "plt.title('Model precision')\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for auc\n",
    "plt.plot(history.history['AUC'])\n",
    "plt.plot(history.history['val_AUC'])\n",
    "plt.title('Model AUC')\n",
    "plt.ylabel('AUC')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Segundo teste\n",
    "* CNN mais robusta:\n",
    "```\n",
    "    classifier = Sequential()\n",
    "\n",
    "    # 1s conv layer\n",
    "    classifier.add(Conv2D(filters=64, kernel_size=(7,7), activation='relu', input_shape=(384, 384, 3), strides=3))\n",
    "    # pooling layer\n",
    "    classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    # 2nd conv layer\n",
    "    classifier.add(Conv2D(128, (3,3), activation='relu'))\n",
    "    classifier.add(Conv2D(128, (3,3), activation='relu'))\n",
    "    classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    # 3rd conv layer\n",
    "    classifier.add(Conv2D(256, (3,3), activation='relu'))\n",
    "    classifier.add(Conv2D(256, (3,3), activation='relu'))\n",
    "    classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    # Flatten\n",
    "    classifier.add(Flatten())\n",
    "    classifier.add(Dense(units=64, activation='relu'))\n",
    "    classifier.add(Dropout(rate=0.5))\n",
    "\n",
    "    # Hidden layer\n",
    "    classifier.add(Dense(units=64, activation='relu'))\n",
    "    classifier.add(Dropout(rate=0.5))\n",
    "    classifier.add(Dense(units=32, activation='relu'))\n",
    "\n",
    "    # Output layer\n",
    "    classifier.add(Dense(9, activation='softmax'))\n",
    "\n",
    "    # Compile network\n",
    "    classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "```\n",
    "  * Com split estratificado;\n",
    "  * Com o **1° conjunto** de transformações de data augmentation:\n",
    "    * Acurácia do teste: 61,52%"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "  * Com o **2° conjunto** de transformações de data augmentation:\n",
    "    * Acurácia do teste: 63,18%"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Primeiro teste\n",
    "* CNN simples, com duas camadas conv. seguidas de duas camadas densas;\n",
    "  * Utilizada apenas para verificações iniciais.\n",
    "* Sem split estratificado;\n",
    "* Sem data augmentation;"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}